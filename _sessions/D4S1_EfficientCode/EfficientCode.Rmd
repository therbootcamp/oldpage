---
title: "Efficient code"
subtitle: ""
author: "The R Bootcamp<br/>Twitter: <a href='https://twitter.com/therbootcamp'>@therbootcamp</a>"
date: "September 2017"
output:
  xaringan::moon_reader:
    css: ["default", "my-theme.css"]
    lib_dir: libs
    nature:
      highlightStyle: github
      highlightLines: true
      countIncrementalSlides: false
      ratio: '16:9'
---



```{r setup, include=FALSE}
options(htmltools.dir.version = FALSE)
# see: https://github.com/yihui/xaringan
# install.packages("xaringan")
# see: 
# https://github.com/yihui/xaringan/wiki
# https://github.com/gnab/remark/wiki/Markdown
options(width=110)
options(digits = 4)
```

# What is efficient code?

.pull-left4[
><font size = 5>"Programmers waste enormous amounts of time thinking about, or worrying about, the speed of noncritical parts of their programs, and these attempts at efficiency actually have a strong negative impact when debugging and maintenance are considered."<br>
><font size = 5>-- Donald Knuth
]

.pull-right5[
<img src="https://raw.githubusercontent.com/therbootcamp/therbootcamp.github.io/master/_sessions/_image/donald_knuth.jpeg" width="500">
<p align="center"><font size=3>Donald E. Knuth<br>Author of <a href:"https://de.wikipedia.org/wiki/The_Art_of_Computer_Programming">The Art of Programming</a><br>source<a href="http://www-cs-faculty.stanford.edu/"> http://www-cs-faculty.stanford.edu/</a>
]

---

# Why is R slow? And, is it?

.pull-left45[
><font size = 5>R is not a fast language. This is not an accident. R was purposely designed to make data analysis and statistics easier for you to do. It was not designed to make life easier for your computer. While R is slow compared to other programming languages, for most purposes, itâ€™s fast enough.
><font size = 5>-- Hadley Wickham
]

.pull-right45[
<font size = 5>*Reasons for R being slow*<br><br>
**Extreme dynamism** - allows you to code flexibly.
<br2>
**Name lookup** (in environments) - allows you to import packages and name your objects flexibly.
]

---

# Profiling

The first step to making your code efficient is to **identify critical parts** of your code. Do this using one of the following: 

| Function| Package| Description| 
|:------|:------|:------------|
| `proc.time()`  |`base`|Returns the time.|
| `system.time()`| `base`|Runs one expression once and returns elapsed CPU time|
| `microbenchmark()`|`microbenchmark`| Runs one or many expressions multiple times and returns statistics on elapsed time.|
| `lineprof(), shine()`|`lineprof`| Evaluates entire scripts. (From Hadley's Github)|

---

# Profiling: Example

Often some small part of your code takes orders of magnitudes longer than everything else. Profiling is about figuring out which parts of your code take so long.

.pull-left4[
```{r, eval = F}

  # load data
  data <- read_csv('titanic.csv')
  
  # remove first column
  data <- data[,-1]
  
  # mutate
  data <- data %>% 
    mutate(months = Age * 12)

  # multiple regression 
  model <- glm(Survived ~ Sex * Age, 
              data = data, 
              family = 'binomial')
  
  # evaluate model
  summary(model)

```
]

.pull-right5[
<img src="https://raw.githubusercontent.com/therbootcamp/therbootcamp.github.io/master/_sessions/_image/lineprof.png" width="500">
]

---

# Improving performance

<font size = 4><i>beginner</i><br>
<font size = 6>
1. Look for existing solutions<br>
2. Do less work<br>
3. Vectorise<br>
4. Parallelise<br>
5. Avoid copies<br>
6. Byte-code compile<br>
</font>
<br>

<font size = 4><i>advanced</i><br>
<font size = 6>
7. Rcpp<br>
8. Using a different R<br>
</font>
---

# Look for an existing solution

.pull-left3[
Almost always your problem has been solved by someone else.

<font size = 4><i>Look for solutions in:</i></font>

**Base R** which can be amazingly fast.

**Other packages** which often provide faster versions of one and the same function.

<a href="http://google.com" align="center">**google**</a>, <a href="http://stackoverflow.com" align="center">**stackoverflow**</a>, <a href="http://rseek.org/" align="center">**rseek**</a>  

]


.pull-right6[
<div style="margin:0px auto; width:100%; float:right">
  <div style="float:left"; margin:0; width:48%">
    <img src="https://raw.githubusercontent.com/therbootcamp/therbootcamp.github.io/master/_sessions/_image/stacksite.png" height="360" width="310" align="center"><br>
    <p align = "center"><a href="stackoverflow.com" align="center"><font size = 3>https://stackoverflow.com</font></a></p>
  </div>
  <div style="float:right"; margin:0; width:48%">
  <img src="https://raw.githubusercontent.com/therbootcamp/therbootcamp.github.io/master/_sessions/_image/rseeksite.png" height="360" width="310" align="center"><br>
    <p align = "center"><a href="http://rseek.org" align="center"><font size = 3>http://rseek.org</font></a></p>
  </div>
</div>

]

---

# Do as little as possible

.pull-left35[
### Or be as specific as possible

Use **tailor-made** functions, e.g., `.subset2()`.

**Provide focus**, e.g., `unlist(x, use.names = F)` vs. `unlist()`.

**Don't repeat** code.
]

.pull-right65[
```{r, echo=F,warning=F,message=F}
require(readr)
require(microbenchmark)
require(data.table)
options(digits=3)
```

```{r, warning=F, message=F, eval = T}
# load package
library(microbenchmark, quietly = T)

# define link to data
link <- 'http://tinyurl.com/y99aj5ed'

# microbenchmark
microbenchmark(
  web   = read_csv(link),
  local = read_csv('data/titanic.csv'),
  fread = fread('data/titanic.csv'),
  times = 10)

```
]


---

# Vectorise

.pull-left35[
Whenever possible **use vector operations** or functions do vectorized operations. 

In other words, **don't use loops** and stay away from all **apply idoms**, such as `apply()`, `sapply()`, `tapply()`, etc.
]

.pull-right6[

```{r, warning=F, message=F, eval = T}
# create data
my_data <- matrix(rnorm(1000000), ncol = 10)

# microbenchmark
microbenchmark(
  colMeans = colMeans(my_data), 
  apply = apply(my_data, 2, mean),
  times = 10)
```
]

---

.pull-left3[

# Avoid copies

**R always copies.** 

whenever using c(), cbind(), rbind(), paste() R creates a copy large enough to contain its inputs.

]


.pull-right65[


```{r, message=F, warning=F, eval = T}
# define character vectors
letters10  <- LETTERS[sample(1:26, 10, replace = T)]
letters100 <- LETTERS[sample(1:26, 100, replace = T)] 

# define collapse function
collapse <- function(x) {
  my_string <- ''
  for(i in 1:length(x)) paste(my_string, x, sep = "")
}

# microbenchmark
microbenchmark(
  loop10  = collapse(letters10),
  loop100 = collapse(letters100),
  vec10   = paste(letters10, collapse = ""),
  vec100  = paste(letters100, collapse = "")
)
```

]
---
.pull-left2[
# Byte-code<br>compilation

Using the base R package `compiler` code can be compiled to byte-code, a faster, **lower-level version of the code**.

As R compiles functions anyway after the first execution, this is **often not useful**. 

]
.pull-right7[
```{r, message=F, warning=F, eval = T}
# define unneccessarily complex function and compile
my_fun <- function(x, f, ...) {
  for (i in seq_along(x)) f(x[[i]], ...)
  }
my_fun_c <- compiler::cmpfun(my_fun)

# define some awfully complex data
x <- list(1:10, letters, c(F, T), NULL)

# microbenchmark
microbenchmark(my_fun(x, is.null), my_fun_c(x, is.null), unit='us')

# microbenchmark again
microbenchmark(my_fun(x, is.null), my_fun_c(x, is.null), unit='us')
```
]
---

.pull-left2[
# Parallel<br>computing

When working with large data one of the **best way to speed up** execution is parallel execution. 

Parallel execution splits the data in many **jobs** and then has many **workers** (separate R instances) working on them in parallel. 
]

.pull-right7[
```{r, message=F, warning=F, eval = T}
# define data and splitted data (jobs)
data       <- matrix(rnorm(10000000), ncol = 10)
split_data <- lapply(1:10, function(i) data[(1:1000)+(i-1)*1000, ])

# open cluster 
require(parallel)
clu <- makeCluster(5)

# my cluster fun
my_cluster_fun <- function(split_data){

  # apply cluster function
  out <- clusterApplyLB(clu, split_data, colMeans)
  
  # combine results
  colMeans(do.call(rbind, out))
  }

# microbenchmark
microbenchmark(vectorz = colMeans(data),
               cluster = my_cluster_fun(split_data))
```
]
---

.pull-left2[
# Rcpp

Another very effective, but highly advanced option is to write the essential code using Rcpp - **R's C++ interface**.

As many functions are already implemented in C++ or Fortran in the background, this works well **only for non-standard operations**. 

<a href="http://dirk.eddelbuettel.com/code/rcpp/Rcpp-quickref.pdf">**Quick-Guide**</a>

]

.pull-right7[
```{r, message=F, warning=F, eval = T}
# define data
my_data <- matrix(rnorm(10000000),ncol = 10)

# define function
my_Rcpp_fun = "
NumericVector colMeans_c(NumericMatrix x){
  NumericVector out(x.ncol());
  for(int j = 0; j < x.ncol(); ++j){
    double m = 0;
    for(int i = 0; i < x.nrow(); ++i) m += x(i, j);
  out[j] = m / x.nrow(); 
  }
return out;
}"

# compile function
require(Rcpp) ; cppFunction(my_Rcpp_fun)

# microbenchmark
microbenchmark(vectorz = colMeans(my_data),
               Rcpp = colMeans_c(my_data))
```
]
---

# Alternative R implementations

from <a href="http://adv-r.had.co.nz/Performance.html"> **Advanced R**</a>

| R implementation| Author | Description| 
|:------|:------|:------------|
| `pqR`  |Radford Neal|Built on top of R 2.15.0, it fixes many obvious performance issues, and provides better memory management and some support for automatic multithreading.|
| `Renjin`  |BeDataDriven| Renjin uses the Java virtual machine, and has an extensive test suite.|
| `FastR`  |Purdue University| FastR is similar to Renjin, but it makes more ambitious optimisations and is somewhat less mature.|
| `Riposte`  |Justin Talbot and Zachary DeVito| Riposte is experimental and ambitious. For the parts of R it implements, it is extremely fast. Riposte is described in more detail in Riposte: A Trace-Driven Compiler and Parallel VM for Vector Code in R.|

---

# Practical

<p><font size=6><b><a href="https://therbootcamp.github.io/_sessions/D4S1_EfficientCode/EfficientCode_practical.html">Link to practical</a>
